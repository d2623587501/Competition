{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1 比赛页面传送门： \n",
    "[遥感影像地块分割](https://aistudio.baidu.com/aistudio/competition/detail/63)\n",
    "### 2 赛题介绍：\n",
    "本赛题由 2020 CCF BDCI 遥感影像地块分割 初赛赛题改编而来。遥感影像地块分割, 旨在对遥感影像进行像素级内容解析，对遥感影像中感兴趣的类别进行提取和分类，在城乡规划、防汛救灾等领域具有很高的实用价值，在工业界也受到了广泛关注。现有的遥感影像地块分割数据处理方法局限于特定的场景和特定的数据来源，且精度无法满足需求。因此在实际应用中，仍然大量依赖于人工处理，需要消耗大量的人力、物力、财力。本赛题旨在衡量遥感影像地块分割模型在多个类别（如建筑、耕地、林地等）上的效果，利用人工智能技术，对多来源、多场景的异构遥感影像数据进行充分挖掘，打造高效、实用的算法，提高遥感影像的分析提取能力。 赛题任务 本赛题旨在对遥感影像进行像素级内容解析，并对遥感影像中感兴趣的类别进行提取和分类，以衡量遥感影像地块分割模型在多个类别（如建筑、耕地、林地等）上的效果。\n",
    "\n",
    "### 3 数据说明\n",
    " 本赛题提供了多个地区已脱敏的遥感影像数据，各参赛选手可以基于这些数据构建自己的地块分割模型。 \n",
    "\n",
    "#### 3.1 训练数据集文件名称：train_and_label.zip，包含2个子文件，分别为：训练数据集（原始图片）文件、训练数据集（标注图片）文件，详细介绍如下：\n",
    "\n",
    "* **训练数据集**（原始图片）文件名称：img_train\n",
    "\n",
    "包含66,653张分辨率为2m/pixel，尺寸为256 * 256的JPG图片，每张图片的名称形如T000123.jpg。\n",
    "\n",
    "* **训练数据集**（标注图片）文件名称：lab_train\n",
    "\n",
    "包含66,653张分辨率为2m/pixel，尺寸为256 * 256的PNG图片，每张图片的名称形如T000123.png。\n",
    "\n",
    "备注： 全部PNG图片共包括4种分类，像素值分别为0、1、2、3。此外，像素值255为未标注区域，表示对应区域的所属类别并不确定，在评测中也不会考虑这部分区域。\n",
    "\n",
    "* **测试数据集**\n",
    "测试数据集文件名称：img_test.zip，详细介绍如下：\n",
    "\n",
    "包含4,609张分辨率为2m/pixel，尺寸为256 * 256的JPG图片，文件名称形如123.jpg。、\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 4 成绩\n",
    "- 当前排名5月份第2\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/86db76f943c748308218c7bd5a9c3f1eb1a7c374f99c4c1489fc3babe2feb793)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 5 模型简介DeepLabv3p（DeepLabv3+）\n",
    "- [原论文链接](https://arxiv.org/pdf/1802.02611.pdf)\n",
    "- DeepLab v3+ 是DeepLab语义分割系列网络的最新作，其前作有 DeepLab v1，v2, v3, 在最新作中，Liang-Chieh Chen等人通过encoder-decoder进行多尺度信息的融合，同时保留了原来的空洞卷积和ASSP层， 其骨干网络使用了Xception模型，提高了语义分割的健壮性和运行速率。结构如下。\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/c393c305d4e94cc0b34079531b5c125f0c3392d1b7174c2991d634576623d257)\n",
    "#### 5.1 编解码器（Encoder-Decoder）\n",
    "- 为了解决上面提到的DeepLabV3在分辨率图像的耗时过多的问题，DeepLabV3+在DeepLabV3的基础上加入了编码器。具体操作见论文中的下图：\n",
    "- DeepLab v3+在主干网络之后连接了Encoder和Decoder，能够在扩大网络感受的同时获得更加高清的分割结果。\n",
    "- 其中，(a)代表SPP结构，其中的8x是直接双线性插值操作，不用参与训练。(b)是编解码器，融集合了高层和低层信息。(c)是DeepLabv3+采取的结构。\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/f6f72770db0145babee8a0fc35a6e8640a26406643a647e5a67db3bcfaa8084e)\n",
    "- 编码器部分，实际上就是DeepLabV3网络。首先选一个低层级的feature用1 * 1的卷积进行通道压缩（原本为256通道，或者512通道），目的是减少低层级的比重。论文认为编码器得到的feature具有更丰富的信息，所以编码器的feature应该有更高的比重,这样做有利于训练。\n",
    "- 解码器部分，直接将编码器的输出上采样4倍，使其分辨率和低层级的feature一致。举个例子，如果采用resnet conv2 输出的feature，则这里要4×4上采样。将两种feature连接后，再进行一次 3×3的卷积（细化作用），然后再次上采样就得到了像素级的预测。\n",
    "#### 5.2 主干网络\n",
    "- 论文受到MSRA组在Xception上改进工作可变形卷积(Deformable-ConvNets)启发，Deformable-ConvNets对Xception做了改进，能够进一步提升模型学习能力，新的结构如下：\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/21eb9ac43cd54e0f9e8f211e6c2598c4c10f9d439b6a42d39955eed46a588755)\n",
    "- 最终，论文使用了如下的改进：\n",
    "- 更深的Xception结构，不同的地方在于不修改entry flow network的结构，为了快速计算和有效的使用内存\n",
    "- 所有的max pooling结构被stride=2的深度可分离卷积代替\n",
    "- 每个3x3的depthwise convolution都跟BN和Relu\n",
    "- 最后将改进后的Xception作为encodet主干网络，替换原本DeepLabv3的ResNet101。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 6 代码实现应用\n",
    "#### 6.1 导入相关包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install paddlex -i https://mirror.baidu.com/pypi/simple\r\n",
    "!pip install imgaug -i https://mirror.baidu.com/pypi/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def convert_to_list(value, n, name, dtype=np.int):\n"
     ]
    }
   ],
   "source": [
    "# 导入包\r\n",
    "import matplotlib\r\n",
    "import os\r\n",
    "import paddlex as pdx\r\n",
    "import paddle.fluid as fluid\r\n",
    "import imgaug.augmenters as iaa\r\n",
    "import numpy as np\r\n",
    "# 设置使用0号GPU卡（如无GPU，执行此代码后仍然会使用CPU训练模型）\r\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 6.2 数据处理与增强\n",
    "[API文档](https://paddlex.readthedocs.io/zh_CN/develop/apis/transforms/seg_transforms.html)\n",
    "\n",
    "对用于分割任务的数据进行操作。可以利用Compose类将图像预处理/增强操作进行组合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddlex.seg import transforms  # 语义分割\r\n",
    "train_transforms = transforms.Compose([\r\n",
    "    transforms.RandomHorizontalFlip(),   # 以一定概率对图像进行水平翻转，参数prob（float）：随机水平翻转概率，默认0.5\r\n",
    "    transforms.Resize(target_size=256),  # 调整图像大小\r\n",
    "    # transforms.RandomPaddingCrop(crop_size=256),  # 随机裁剪，当所需要的裁剪尺寸大于原图，则进行padding操作\r\n",
    "    #transforms.RandomBlur(prob=0.1),  # 以一定概率对图像进行高斯模糊，参数prob（float）：图像模糊概率，默认0.1\r\n",
    "    #transforms.RandomRotate(rotate_range=15),  # 对图像进行随机旋转，当存在标注图像时，同步进行，并对旋转后的图像进行padding\r\n",
    "    # transforms.RandomDistort(brightness_range=0.5),  # 以一定概率对图像进行随机像素内容变换，该方法必须在Normalize之前使用\r\n",
    "    transforms.Normalize()  # 归一化\r\n",
    "])\r\n",
    "eval_transforms = transforms.Compose([\r\n",
    "    transforms.Resize(256),\r\n",
    "    transforms.Normalize()\r\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 6.3 数据集处理\n",
    "将数据图片和标签拼接，划分数据集，生成train_list.txt、valid_list.txt\n",
    "\n",
    "[paddlex.datasets的说明文档](https://paddlex.readthedocs.io/zh_CN/develop/apis/datasets.html )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 数据集的解压\r\n",
    "# !unzip data/data81053/img_test.zip\r\n",
    "# !unzip data/data81053/train_and_label.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 66652\n",
      "img_train/T145589.jpg\n",
      "lab_train/T145589.png\n"
     ]
    }
   ],
   "source": [
    "datas = []\r\n",
    "# 定义训练图片和标签\r\n",
    "image_base = 'img_train'\r\n",
    "annos_base = 'lab_train'\r\n",
    "# os.listdir() 方法用于返回指定的文件夹包含的文件或文件夹的名字的列表。这个列表以字母顺序。 它不包括 '.' 和'..' 即使它在文件夹中\r\n",
    "ids_ = [v.split('.')[0] for v in os.listdir(image_base)]\r\n",
    "\r\n",
    "for id_ in ids_:\r\n",
    "    img_pt0 = os.path.join(image_base, '{}.jpg'.format(id_))  # os.path.join() 方法把目录和文件名合成一个路径\r\n",
    "    img_pt1 = os.path.join(annos_base, '{}.png'.format(id_))\r\n",
    "    datas.append((img_pt0.replace('/home/aistudio/work/', ''), img_pt1.replace('/home/aistudio/work/', '')))  # 将 img_pt0和 img_pt1连接\r\n",
    "    if os.path.exists(img_pt0) and os.path.exists(img_pt1):  # os.path.exists（）路径存在则返回True,路径损坏返回False\r\n",
    "        pass\r\n",
    "    else:\r\n",
    "        raise \"path invalid!\"\r\n",
    "\r\n",
    "print('total:', len(datas))\r\n",
    "print(datas[0][0])\r\n",
    "print(datas[0][1])\r\n",
    "\r\n",
    "data_dir = '/home/aistudio/work/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 65986\n",
      "valid: 666\n"
     ]
    }
   ],
   "source": [
    "# 给图像标签赋予含义\r\n",
    "labels = [\r\n",
    "    '建筑', '耕地', '林地',\r\n",
    "    '其他'\r\n",
    "]\r\n",
    "# 标签写入labels.txt文件\r\n",
    "with open('labels.txt', 'w') as f:\r\n",
    "    for v in labels:\r\n",
    "        f.write(v+'\\n')\r\n",
    "# 将数据进行打乱\r\n",
    "np.random.seed(5)\r\n",
    "np.random.shuffle(datas)\r\n",
    "# 将数据划分为训练集和测试集\r\n",
    "split_num = int(0.01*len(datas))\r\n",
    "\r\n",
    "train_data = datas[:-split_num]\r\n",
    "valid_data = datas[-split_num:]\r\n",
    "# 将训练集写入train_list.txt\r\n",
    "with open('train_list.txt', 'w') as f:\r\n",
    "    for img, lbl in train_data:\r\n",
    "        f.write(img + ' ' + lbl + '\\n')\r\n",
    "# 将测试集写入valid_list.txt\r\n",
    "with open('valid_list.txt', 'w') as f:\r\n",
    "    for img, lbl in valid_data:\r\n",
    "        f.write(img + ' ' + lbl + '\\n')\r\n",
    "\r\n",
    "print('train:', len(train_data))\r\n",
    "print('valid:', len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-02 00:56:38 [INFO]\t65986 samples in file train_list.txt\n",
      "2021-06-02 00:56:38 [INFO]\t666 samples in file valid_list.txt\n"
     ]
    }
   ],
   "source": [
    "data_dir = './'\r\n",
    "# paddlex.datasets.SegDataset()用于语义分割模型\r\n",
    "train_dataset = pdx.datasets.SegDataset(\r\n",
    "    data_dir=data_dir,  # 数据集路径\r\n",
    "    file_list='train_list.txt',  # 描述数据集图片文件和对应标注文件的文件路径\r\n",
    "    label_list='labels.txt',  # 描述数据集包含的类别信息文件路径\r\n",
    "    transforms=train_transforms,  # 数据集中每个样本的预处理/增强算子\r\n",
    "    shuffle=True)  #是否需要对数据集中样本打乱顺序。默认为False\r\n",
    "    \r\n",
    "eval_dataset = pdx.datasets.SegDataset(\r\n",
    "    data_dir=data_dir,\r\n",
    "    file_list='valid_list.txt',\r\n",
    "    label_list='labels.txt',\r\n",
    "    transforms=eval_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 6.4 使用DeepLabv3p+Xception65进行训练\n",
    "[模型API](https://paddlex.readthedocs.io/zh_CN/develop/apis/models/semantic_segmentation.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_classes_1 = len(train_dataset.labels)\r\n",
    "regularizer_1=fluid.regularizer.L2DecayRegularizer(regularization_coeff=0.3)\r\n",
    "model = pdx.seg.DeepLabv3p(\r\n",
    "    num_classes=num_classes_1,  backbone='Xception65'\r\n",
    ")\r\n",
    "\r\n",
    "model.train(\r\n",
    "    num_epochs=50,  # 训练迭代轮数\r\n",
    "    train_dataset=train_dataset,  # 训练数据读取器\r\n",
    "    train_batch_size=16,  #训练数据batch大小，同时作为验证数据batch大小。默认32\r\n",
    "    eval_dataset=eval_dataset,  # 评估数据读取器\r\n",
    "    save_interval_epochs=2,  # 模型保存间隔，默认1\r\n",
    "    log_interval_steps=200,  # 训练日志输出间隔，默认2\r\n",
    "    save_dir='output/deeplab',  # 模型保存路径\r\n",
    "    pretrain_weights='COCO',  # coco数据集预训练权重\r\n",
    "    optimizer = fluid.optimizer.MomentumOptimizer(learning_rate=3e-3, momentum=0.91, use_nesterov=True),\r\n",
    "    lr_decay_power=0.925,\r\n",
    "    use_vdl=True,,\r\n",
    "    eval_metric_loss=0.002,\r\n",
    "    early_stop=True,\r\n",
    "    early_stop_patience=4\r\n",
    ")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.evaluate(eval_dataset, batch_size=1, epoch_id=None, return_details=False)\r\n",
    "# eval_dataset (paddlex.datasets): 评估数据读取器。\r\n",
    "# batch_size (int): 评估时的batch大小。默认1。\r\n",
    "# epoch_id (int): 当前评估模型所在的训练轮数。\r\n",
    "# return_details (bool): 是否返回详细信息。默认False。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-02 13:43:47 [INFO]\tModel[DeepLabv3p] loaded.\n"
     ]
    }
   ],
   "source": [
    "# 保存模型\r\n",
    "model = pdx.load_model('./output/deeplab/best_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 6.5 执行预测并保存数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 1429/4608 [00:25<00:59, 53.62it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  # tqdm 是一个快速，可扩展的Python进度条，可以在 Python 长循环中添加一个进度提示信息，用户只需要封装任意的迭代器 tqdm(iterator)。\r\n",
    "import cv2\r\n",
    "\r\n",
    "test_base = 'img_testA/'\r\n",
    "out_base = 'ccf_baidu_remote_sense/result/'\r\n",
    "\r\n",
    "if not os.path.exists(out_base):  # 判断out_base的路径是否存在\r\n",
    "    os.makedirs(out_base)  # os.makedirs() 方法用于递归创建目录\r\n",
    "\r\n",
    "\r\n",
    "for im in tqdm(os.listdir(test_base)):  # os.listdir()返回path指定的文件夹包含的文件或文件夹的名字的列表\r\n",
    "    if not im.endswith('.jpg'):  # 判断文件名后缀\r\n",
    "        continue\r\n",
    "    pt = test_base + im\r\n",
    "    result = model.predict(pt)  # 使用训练好的模型\r\n",
    "    cv2.imwrite(out_base+im.replace('jpg', 'png'), result['label_map'])  #  cv2.imwrite()保存图像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 小结\n",
    "> - 授之以鱼不如授之以渔\n",
    "> - 不要单纯跑通项目提个比赛成绩就结束了，要学习模型架构的理念知识，要学会查询API并使用的方法（项目中我将使用到的API链接放上了），那么后期才能对模型架构进行改进。\n",
    "> - 如若存在问题，可在评论区留言，作者会不时为大家讲解\n",
    "> - 作者aistudio主页链接，欢迎各位互粉、提问：[aistudio](https://aistudio.baidu.com/aistudio/personalcenter/thirdview/539945)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
